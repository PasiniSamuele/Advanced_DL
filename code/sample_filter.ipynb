{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"../datasets/Surprise_only/\"\n",
    "model_dir = \"models/Fer2013_merge_selected_85_uniform/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def __init__(self, loss_function, metrics):\n",
    "        super().__init__()\n",
    "        self.loss_function = loss_function\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = self.loss_function(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = self.loss_function(out, labels)   # Calculate loss\n",
    "        result = {'val_loss': loss.detach()}\n",
    "        \n",
    "        for m in self.metrics:\n",
    "            result[m.name] = m.eval(out, labels)           # Calculate metrics\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        \n",
    "        result = {'val_loss': epoch_loss.item()}\n",
    "        \n",
    "        for m in self.metrics:\n",
    "            batch = [x[m.name] for x in outputs]\n",
    "            epoch = torch.stack(batch).mean()      # Combine metrics\n",
    "            result[m.name] = epoch.item()\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        out = f\"Epoch [{epoch}]\"\n",
    "        vals = list(result.keys())\n",
    "        for v in vals:\n",
    "            out += f\", {v}: {result[v]:.3e}\"\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(ImageClassificationBase):\n",
    "    \n",
    "    def __init__(self, loss_function, metrics, out_size):\n",
    "        super().__init__(loss_function, metrics)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3,stride=2, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3,stride=2, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.norm3 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(in_features=128*5*5, out_features=256)\n",
    "        #self.fc2 = nn.Linear(in_features=256, out_features=256)\n",
    "        self.fc = nn.Linear(256, out_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.norm1(self.pool1(F.relu(self.conv1(input))))\n",
    "        output = self.norm2(self.pool2(F.relu(self.conv2((output)))))\n",
    "        output = self.norm3(self.pool3(F.relu(self.conv3((output)))))\n",
    "        output = output.view(-1, 128*5*5)\n",
    "        output = F.relu(self.fc1(output))\n",
    "        #output = F.relu(self.fc2(output))\n",
    "        output = self.fc(output)\n",
    "        output = F.softmax(input = output, dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = ImageFolder(root=dataset, transform=transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                     transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df_test.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 5168}\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.9350e-04])\n"
     ]
    }
   ],
   "source": [
    "counts = dict(Counter(df_test.targets))\n",
    "print(counts)\n",
    "weights = np.array(list(counts.values()))\n",
    "weights = torch.Tensor( min(weights)/weights)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DeviceDataLoader(DataLoader(df_test, batch_size=batch_size, shuffle=False),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for fold, model in enumerate(os.listdir(model_dir)):\n",
    "    net = Net(nn.CrossEntropyLoss(weights), [], 7)\n",
    "    net.load_state_dict(torch.load(os.path.join(model_dir,model)))\n",
    "    net.eval()\n",
    "    net.cuda()\n",
    "    models.append( net )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predicitons(model, dataset):\n",
    "    y_test = []\n",
    "    y_scores = []\n",
    "\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataset):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            y_test.extend(labels.tolist())\n",
    "            y_scores.extend(outputs.tolist())\n",
    "\n",
    "    y_test = np.array(y_test)\n",
    "    y_scores = np.array(y_scores)\n",
    "\n",
    "    return y_test, y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e887f8ec49ee4fcb95cb87bb4cf6e9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483aedec875c40d3a4e64d46244906d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9d9e333fd34943ad68170a9320dbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb623bcd7214eb1884ab2ca2bdb5a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_tests = []\n",
    "y_scoress = []\n",
    "for model in models:\n",
    "    y_test, y_scores = get_model_predicitons(model,test_dl)\n",
    "    y_tests.append(y_test)\n",
    "    y_scoress.append(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5174,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tests[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = dict()\n",
    "for i,c in enumerate(classes):\n",
    "    distr[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5174"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tests[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_correctness =[]\n",
    "for i in range(y_tests[0].shape[0]):\n",
    "    res = [y_scoress[fold][i,y_tests[fold][i]] for fold in range(len(y_tests))]\n",
    "    img_correctness.append(np.mean(res))\n",
    "    distr[y_tests[fold][i]].append(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i,c in enumerate(classes):\\n    plt.hist(distr[i], bins=20)\\n    plt.title(f\"Histogram for class {c}\")\\n    plt.show()'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i,c in enumerate(classes):\n",
    "    plt.hist(distr[i], bins=20)\n",
    "    plt.title(f\"Histogram for class {c}\")\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5174"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new = \"../datasets/Surprise_only_filtered\"\n",
    "os.makedirs(dataset_new, exist_ok=True)\n",
    "for c in classes:\n",
    "    os.makedirs(os.path.join(dataset_new,c), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for img, prob in enumerate(img_correctness):\\n\\n    if prob>0.4:\\n        class_path = os.path.join(dataset_new,classes[y_tests[0][img]])\\n        img_name = test_dl.dl.dataset.imgs[img][0]\\n        shutil.copy(img_name, os.path.join(class_path, img_name.split(\"\\\\\")[-1] ))'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_img_correctness = np.argsort(img_correctness)[::-1]\n",
    "for i in range(20):\n",
    "    print(img_correctness[ordered_img_correctness[i]])\n",
    "'''for img, prob in enumerate(img_correctness):\n",
    "\n",
    "    if prob>0.4:\n",
    "        class_path = os.path.join(dataset_new,classes[y_tests[0][img]])\n",
    "        img_name = test_dl.dl.dataset.imgs[img][0]\n",
    "        shutil.copy(img_name, os.path.join(class_path, img_name.split(\"\\\\\")[-1] ))'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1500\n",
    "\n",
    "indexes = ordered_img_correctness[:K]\n",
    "for a, i in enumerate(indexes):\n",
    "    class_path = os.path.join(dataset_new,classes[y_tests[0][i]])\n",
    "    img_name = test_dl.dl.dataset.imgs[i][0]\n",
    "    name = img_name.split(\"\\\\\")[-1]\n",
    "    shutil.copy(img_name, os.path.join(class_path, f'{a}_{name}' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi Ã¨ verificato un arresto anomalo del kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. Esaminare il codice nelle celle per identificare una possibile causa dell'errore. Per altre informazioni, fare clic su <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a>. Per altri dettagli, vedere Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "plt.imshow(test_dl.dl.dataset.imgs[indexes[K-1]][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83305284921c5efca5a091fd9f3cbcdce3021b30adb0589d0b23bb1c455d0e53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
