{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30487ab-c2a7-4231-80cd-942fbc97e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import sleep\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084cd3c3-e57c-434e-9669-2ff06fa1d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6e3e39-06fa-4e0b-9a18-7ae66454f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76418ef-1f2e-4e21-b593-8aca2922d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_src = os.path.abspath(\"D:\\Documenti\\GitHub\\Advanced_DL\\datasets\\Fer2013\\\\train\")\n",
    "ds_test_src = os.path.abspath(\"D:\\Documenti\\GitHub\\Advanced_DL\\datasets\\Fer2013\\\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f983610-8ba7-4afc-81b4-44c255c5257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ImageFolder(root=ds_train_src, transform=ToTensor())\n",
    "df_test = ImageFolder(root=ds_test_src, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f96e28-c09a-4c5f-836b-51ea2ae0ed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df_train.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fab602f-e6fa-46f2-898c-ad2d697ed41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(DataLoader(df_train, batch_size=64, shuffle=True),device)\n",
    "test_dl = DeviceDataLoader(DataLoader(df_test, batch_size=64, shuffle=True),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507d69b6-d282-4f45-88a6-efff99d18dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(train_dataloader)\n",
    "# images, labels = dataiter.next()\n",
    "# print(type(images))\n",
    "# print(images.shape)\n",
    "# print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1042dd71-2d30-4b9e-b7fd-dc0178421675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def eval(self, outputs, labels):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ab563e9-aeac-45c8-a5da-e99f8cbc54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(Metric):\n",
    "    \n",
    "    def eval(self, outputs, labels):\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1977248f-bcac-4d98-806b-013f3fa7e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def __init__(self, loss_function, metrics):\n",
    "        super().__init__()\n",
    "        self.loss_function = loss_function\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = self.loss_function(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = self.loss_function(out, labels)   # Calculate loss\n",
    "        result = {'val_loss': loss.detach()}\n",
    "        \n",
    "        for m in self.metrics:\n",
    "            result[m.name] = m.eval(out, labels)           # Calculate metrics\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        \n",
    "        result = {'val_loss': epoch_loss.item()}\n",
    "        \n",
    "        for m in self.metrics:\n",
    "            batch = [x[m.name] for x in outputs]\n",
    "            epoch = torch.stack(batch).mean()      # Combine metrics\n",
    "            result[m.name] = epoch.item()\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        out = f\"Epoch [{epoch}]\"\n",
    "        vals = list(result.keys())\n",
    "        for v in vals:\n",
    "            out += f\", {v}: {result[v]:.4f}\"\n",
    "        print(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "125ec41f-92e5-4844-bc89-6eeb84c08eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(ImageClassificationBase):\n",
    "    \n",
    "    def __init__(self, loss_function, metrics, out_size):\n",
    "        super().__init__(loss_function, metrics)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1) # (12, 44, 44 )\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1) # (12, 40, 40 )\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.pool = nn.MaxPool2d(2,2)                                                    # (12, 20, 20 )\n",
    "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1) # (24, 16, 16 )\n",
    "        self.bn4 = nn.BatchNorm2d(24)\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1) # (24, 12, 12 )\n",
    "        self.bn5 = nn.BatchNorm2d(24)\n",
    "        self.fc1 = nn.Linear(24*12*12, out_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.relu(self.bn1(self.conv1(input)))      \n",
    "        output = F.relu(self.bn2(self.conv2(output)))     \n",
    "        output = self.pool(output)                        \n",
    "        output = F.relu(self.bn4(self.conv4(output)))     \n",
    "        output = F.relu(self.bn5(self.conv5(output)))    \n",
    "        output = output.view(-1, 24*12*12)\n",
    "        output = self.fc1(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9143406a-6f11-42b7-83c4-b6c671750901",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "metrics = [Accuracy(\"val_acc\")]\n",
    "optimizer = optim.Adam\n",
    "lr =0.001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b210b51-8ff6-46ec-8156-4795f88cd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(loss_function, metrics, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f357986-b273-4935-bbb9-562e4726f03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (loss_function): CrossEntropyLoss()\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=3456, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0a6ad2d-46c4-4553-94e6-5459666c6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in tqdm(range(epochs), desc = \"Current Epoch\"):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in tqdm(train_loader, desc = f\"Epoch: {epoch}\", leave= False):\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94ef4dba-0260-4d4a-947b-52ecf388c783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9be5253fd5439da295e6f3a8b98c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Current Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.3991, val_acc: 0.4583, train_loss: 1.5336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], val_loss: 1.3316, val_acc: 0.4916, train_loss: 1.2987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], val_loss: 1.2684, val_acc: 0.5143, train_loss: 1.1956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], val_loss: 1.2802, val_acc: 0.5183, train_loss: 1.1223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], val_loss: 1.3032, val_acc: 0.5218, train_loss: 1.0620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 5:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], val_loss: 1.2587, val_acc: 0.5291, train_loss: 1.0054\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 6:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], val_loss: 1.3314, val_acc: 0.5121, train_loss: 0.9536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 7:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], val_loss: 1.2749, val_acc: 0.5510, train_loss: 0.8962\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 8:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], val_loss: 1.2854, val_acc: 0.5425, train_loss: 0.8440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 9:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], val_loss: 1.3393, val_acc: 0.5382, train_loss: 0.7935\n"
     ]
    }
   ],
   "source": [
    "history = fit(num_epochs, lr, net, train_dl, test_dl, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80408890-316b-40cd-8fc5-dd52ce74c996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 1.33816397190094, 'val_acc': 0.5381637215614319}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(net, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ff063a8-8125-4c98-a70f-c3b60c2ce7b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):  \u001b[38;5;66;03m# loop over the dataset multiple times\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_dataloader\u001b[49m, \u001b[38;5;241m0\u001b[39m),desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2nd loop\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(train_dataloader, 0),desc='2nd loop'):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1403cef9-c12a-4e66-9565-7f8b7eaf2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_dataloader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b7789-29fe-43c3-9821-11cb5215fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_dataloader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767bda14-919f-42f6-940e-7a31ab451993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
