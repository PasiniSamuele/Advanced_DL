{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # basic parameters\n",
    "    parser.add_argument('--dataroot', required=True, help='path to images (should have subfolders trainA, trainB, valA, valB, etc)')\n",
    "    parser.add_argument('--name', type=str, default='experiment_name', help='name of the experiment. It decides where to store samples and models')\n",
    "    parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
    "    parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n",
    "    # model parameters\n",
    "    parser.add_argument('--model', type=str, default='cycle_gan', help='chooses which model to use. [cycle_gan | pix2pix | test | colorization]')\n",
    "    parser.add_argument('--input_nc', type=int, default=3, help='# of input image channels: 3 for RGB and 1 for grayscale')\n",
    "    parser.add_argument('--output_nc', type=int, default=3, help='# of output image channels: 3 for RGB and 1 for grayscale')\n",
    "    parser.add_argument('--ngf', type=int, default=64, help='# of gen filters in the last conv layer')\n",
    "    parser.add_argument('--ndf', type=int, default=64, help='# of discrim filters in the first conv layer')\n",
    "    parser.add_argument('--netD', type=str, default='basic', help='specify discriminator architecture [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator')\n",
    "    parser.add_argument('--netG', type=str, default='resnet_9blocks', help='specify generator architecture [resnet_9blocks | resnet_6blocks | unet_256 | unet_128]')\n",
    "    parser.add_argument('--n_layers_D', type=int, default=3, help='only used if netD==n_layers')\n",
    "    parser.add_argument('--norm', type=str, default='instance', help='instance normalization or batch normalization [instance | batch | none]')\n",
    "    parser.add_argument('--init_type', type=str, default='normal', help='network initialization [normal | xavier | kaiming | orthogonal]')\n",
    "    parser.add_argument('--init_gain', type=float, default=0.02, help='scaling factor for normal, xavier and orthogonal.')\n",
    "    parser.add_argument('--no_dropout', action='store_true', help='no dropout for the generator')\n",
    "    # dataset parameters\n",
    "    parser.add_argument('--dataset_mode', type=str, default='unaligned', help='chooses how datasets are loaded. [unaligned | aligned | single | colorization]')\n",
    "    parser.add_argument('--direction', type=str, default='AtoB', help='AtoB or BtoA')\n",
    "    parser.add_argument('--serial_batches', action='store_true', help='if true, takes images in order to make batches, otherwise takes them randomly')\n",
    "    parser.add_argument('--num_threads', default=4, type=int, help='# threads for loading data')\n",
    "    parser.add_argument('--batch_size', type=int, default=1, help='input batch size')\n",
    "    parser.add_argument('--load_size', type=int, default=286, help='scale images to this size')\n",
    "    parser.add_argument('--crop_size', type=int, default=256, help='then crop to this size')\n",
    "    parser.add_argument('--max_dataset_size', type=int, default=float(\"inf\"), help='Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.')\n",
    "    parser.add_argument('--preprocess', type=str, default='resize_and_crop', help='scaling and cropping of images at load time [resize_and_crop | crop | scale_width | scale_width_and_crop | none]')\n",
    "    parser.add_argument('--no_flip', action='store_true', help='if specified, do not flip the images for data augmentation')\n",
    "    parser.add_argument('--display_winsize', type=int, default=256, help='display window size for both visdom and HTML')\n",
    "    # additional parameters\n",
    "    parser.add_argument('--epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')\n",
    "    parser.add_argument('--load_iter', type=int, default='0', help='which iteration to load? if load_iter > 0, the code will load models by iter_[load_iter]; otherwise, the code will load models by [epoch]')\n",
    "    parser.add_argument('--verbose', action='store_true', help='if specified, print more debugging information')\n",
    "    parser.add_argument('--suffix', default='', type=str, help='customized suffix: opt.name : opt.name + suffix: e.g., {model}_{netG}_size{load_size}')\n",
    "    # network saving and loading parameters\n",
    "    parser.add_argument('--save_latest_freq', type=int, default=5000, help='frequency of saving the latest results')\n",
    "    parser.add_argument('--save_epoch_freq', type=int, default=5, help='frequency of saving checkpoints at the end of epochs')\n",
    "    parser.add_argument('--save_by_iter', action='store_true', help='whether saves model by iteration')\n",
    "    parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n",
    "    parser.add_argument('--epoch_count', type=int, default=1, help='the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...')\n",
    "    parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')\n",
    "    # training parameters\n",
    "    parser.add_argument('--display_freq', type=int, default=400, help='frequency of showing training results on screen')\n",
    "    parser.add_argument('--print_freq', type=int, default=100, help='frequency of showing training results on console')\n",
    "    parser.add_argument('--n_epochs', type=int, default=100, help='number of epochs with the initial learning rate')\n",
    "    parser.add_argument('--n_epochs_decay', type=int, default=100, help='number of epochs to linearly decay learning rate to zero')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n",
    "    parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')\n",
    "    parser.add_argument('--gan_mode', type=str, default='lsgan', help='the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.')\n",
    "    parser.add_argument('--pool_size', type=int, default=50, help='the size of image buffer that stores previously generated images')\n",
    "    parser.add_argument('--lr_policy', type=str, default='linear', help='learning rate policy. [linear | step | plateau | cosine]')\n",
    "    parser.add_argument('--lr_decay_iters', type=int, default=50, help='multiply by a gamma every lr_decay_iters iterations')\n",
    "\n",
    "    parser.add_argument('--num_dense_layers', type=int, default=3, help='number of dense blocks in every RDNB block')\n",
    "    parser.add_argument('--num_dense_subblocks', type=int, default=4, help='number of con-batch-relu in every dense block')\n",
    "    parser.add_argument('--residual_scaling', type=float, default=0.5, help='residual scaling for dense residuals (0-1)')\n",
    "    parser.add_argument('--lambda_A', type=float, default=10.0, help='weight for cycle loss (A -> B -> A)')\n",
    "    parser.add_argument('--lambda_B', type=float, default=10.0, help='weight for cycle loss (B -> A -> B)')\n",
    "    parser.add_argument('--lambda_identity', type=float, default=0.5, help='use identity mapping. Setting lambda_iden')\n",
    "    parser.add_argument('--perc_i', type=int, default=-1, help='')\n",
    "    parser.add_argument('--perc_j', type=int, default=-1, help='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_param = {\n",
    "    'dataroot' : \"../../datasets/Neutral_Surprise_85\",\n",
    "    'name' : \"surprise_emotions_e_ppca85_residual07_identity05_alternate\",\n",
    "    'model' : \"ecycle_gan\",\n",
    "    'input_nc' : 1,\n",
    "    'output_nc' : 1,\n",
    "    'ngf' : 64,\n",
    "    'ndf' : 64,\n",
    "    'netD' : 'n_layers',\n",
    "    'netG' : 'resnet_6blocks',\n",
    "    'n_layers_D' : 2,\n",
    "    'norm' : 'batch',\n",
    "    'init_type' : 'normal',\n",
    "    'init_gain' : 0.02,\n",
    "    'no_dropout' : True,\n",
    "    'direction' : 'AtoB',\n",
    "    'batch_size' : 1,\n",
    "    'load_size' : 48,\n",
    "    'crop_size' : 48,\n",
    "    'preprocess' : 'none',\n",
    "    'no_flip' : True,\n",
    "    'num_dense_subblocks' : 2,\n",
    "    'num_dense_layers' : 2,\n",
    "    'residual_scaling' : 0.7\n",
    "}\n",
    "train_param = {\n",
    "    'display_freq' : 20,\n",
    "    'n_epochs' : 30,\n",
    "    'n_epochs_decay' : 20,\n",
    "    'lr' : 1e-4,\n",
    "    'gan_mode' : 'lsgan',\n",
    "    'pool_size' : 50,\n",
    "    'lr_policy' : 'plateau',\n",
    "    'save_epoch_freq' : 1,\n",
    "    'lambda_A' : 1,\n",
    "    'lambda_B' : 1,\n",
    "    'lambda_identity' : 0.3,\n",
    "    'perc_i' : -1,\n",
    "    'perc_j' : -1,\n",
    "    'phase' : 'train'\n",
    "}\n",
    "test_param = {\n",
    "    'num_test': 50,\n",
    "    'phase' : 'test',\n",
    "    'discrim_path': os.path.join(os.path.join('.\\\\results',base_param['name']),'discrims.json')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --dataroot ../../datasets/Neutral_Surprise_85 --name surprise_emotions_e_ppca85_residual07_identity05_alternate --model ecycle_gan --input_nc 1 --output_nc 1 --ngf 64 --ndf 64 --netD n_layers --netG resnet_6blocks --n_layers_D 2 --norm batch --init_type normal --init_gain 0.02 --no_dropout --direction AtoB --batch_size 1 --load_size 48 --crop_size 48 --preprocess none --no_flip --num_dense_subblocks 2 --num_dense_layers 2 --residual_scaling 0.7 --display_freq 20 --n_epochs 30 --n_epochs_decay 20 --lr 0.0001 --gan_mode lsgan --pool_size 50 --lr_policy plateau --save_epoch_freq 1 --lambda_A 1 --lambda_B 1 --lambda_identity 0.3 --perc_i -1 --perc_j -1 --phase train \n"
     ]
    }
   ],
   "source": [
    "command = \"python train.py \"\n",
    "for k,v in base_param.items():\n",
    "    if type(v)==bool and v:\n",
    "        command += f\"--{k} \"\n",
    "    elif type(v)!=bool:\n",
    "        command += f\"--{k} {v} \"\n",
    "\n",
    "for k,v in train_param.items():\n",
    "    if type(v)==bool and v:\n",
    "        command += f\"--{k} \"\n",
    "    elif type(v)!=bool:\n",
    "        command += f\"--{k} {v} \"\n",
    "\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python test.py --dataroot ../../datasets/Neutral_Surprise_85 --name surprise_emotions_e_ppca85_residual07_identity05_alternate --model ecycle_gan --input_nc 1 --output_nc 1 --ngf 64 --ndf 64 --netD n_layers --netG resnet_6blocks --n_layers_D 2 --norm batch --init_type normal --init_gain 0.02 --no_dropout --direction AtoB --batch_size 1 --load_size 48 --crop_size 48 --preprocess none --no_flip --num_dense_subblocks 2 --num_dense_layers 2 --residual_scaling 0.7 --num_test 50 --phase test --discrim_path .\\results\\surprise_emotions_e_ppca85_residual07_identity05_alternate\\discrims.json \n"
     ]
    }
   ],
   "source": [
    "command = \"python test.py \"\n",
    "for k,v in base_param.items():\n",
    "    if type(v)==bool and v:\n",
    "        command += f\"--{k} \"\n",
    "    elif type(v)!=bool:\n",
    "        command += f\"--{k} {v} \"\n",
    "\n",
    "for k,v in test_param.items():\n",
    "    if type(v)==bool and v:\n",
    "        command += f\"--{k} \"\n",
    "    elif type(v)!=bool:\n",
    "        command += f\"--{k} {v} \"\n",
    "\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83305284921c5efca5a091fd9f3cbcdce3021b30adb0589d0b23bb1c455d0e53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
